{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jamesdavey/20x-faster-pixel-coordinate-generator-3s-runtime?scriptVersionId=122514442\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"## Pixel coordinate generation","metadata":{}},{"cell_type":"markdown","source":"In this notebook, I have rewritten the process for getting pixels coordinates described in the [Tutorial notebook](https://www.kaggle.com/code/jpposma/vesuvius-challenge-ink-detection-tutorial) \n\nThe aim of it is to assist the process of dataset creation described in that notebook, and to rapidly speed it up.\n\nThe original way took ~70 seconds, my way speeds this up by eliminating the need for a loop, allowing it to run in ~3 seconds. Over 20x faster :)\n\nAt the bottom of the notebook I verify both ways produce identical outputs so we can be sure it is working correctly.","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport PIL\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom pathlib import Path\nimport os\nimport time\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"on device: {device}\")\n\ndist_from_centre = 30 # ie. each square into network is 30*2+1=61 wide\nevaluation_rectangle = (1100, 3500, 700, 950) # (x, y, w, h)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T22:48:23.339329Z","iopub.execute_input":"2023-03-17T22:48:23.339939Z","iopub.status.idle":"2023-03-17T22:48:24.583769Z","shell.execute_reply.started":"2023-03-17T22:48:23.339892Z","shell.execute_reply":"2023-03-17T22:48:24.582423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_filepath = '/kaggle/input/vesuvius-challenge-ink-detection/train/1/'\n#['inklabels.png', 'inklabels_rle.csv', 'ir.png', 'mask.png', 'surface_volume']\ntif_filenames = sorted(os.listdir(root_filepath+'surface_volume'))\nprint(len(tif_filenames), tif_filenames[:5])\n\nmask = torch.from_numpy(np.array(PIL.Image.open(root_filepath+\"mask.png\").convert('1')))\nlabel = torch.from_numpy(np.array(PIL.Image.open(root_filepath+\"inklabels.png\"))).float().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T22:48:24.586164Z","iopub.execute_input":"2023-03-17T22:48:24.586785Z","iopub.status.idle":"2023-03-17T22:48:25.357167Z","shell.execute_reply.started":"2023-03-17T22:48:24.586743Z","shell.execute_reply":"2023-03-17T22:48:25.355485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The functions below produce all pixel coordinates for pixels within the rectangle and outside it. (Note: In both coordinates are restricted to the mask)","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.imshow(label.cpu(), cmap = 'gray')\npatch1 = matplotlib.patches.Rectangle((evaluation_rectangle[0], evaluation_rectangle[1]), evaluation_rectangle[2], evaluation_rectangle[3], linewidth=1, edgecolor='r', facecolor='none')\nax.add_patch(patch1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T22:48:25.358777Z","iopub.execute_input":"2023-03-17T22:48:25.359518Z","iopub.status.idle":"2023-03-17T22:48:27.512786Z","shell.execute_reply.started":"2023-03-17T22:48:25.359474Z","shell.execute_reply":"2023-03-17T22:48:27.511461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.imshow(mask, cmap = 'gray')\npatch1 = matplotlib.patches.Rectangle((evaluation_rectangle[0], evaluation_rectangle[1]), evaluation_rectangle[2], evaluation_rectangle[3], linewidth=1, edgecolor='r', facecolor='none')\nax.add_patch(patch1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T22:48:27.515831Z","iopub.execute_input":"2023-03-17T22:48:27.516736Z","iopub.status.idle":"2023-03-17T22:48:29.218533Z","shell.execute_reply.started":"2023-03-17T22:48:27.516674Z","shell.execute_reply":"2023-03-17T22:48:29.217136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pixels():\n    \"\"\"\n    Takes in a mask, and outputs the set of pixels (x,y) in intersection of that mask with a rectangle\n    \"\"\"\n    t1 = time.time()\n    h, w = mask.shape # 8181, 6330\n    full_square = torch.full((h, w, 2), 0, dtype = torch.int)\n    for x in range(w): full_square[:, x, 1] = x # (x, y)\n    for y in range(h): full_square[y, :, 0] = y\n    valid_pixels = full_square.masked_fill(mask.unsqueeze(dim=2) == 0, -1)\n    #Cannot crop border as it will ruin our indexing. Instead we set its values to -1 (i.e. outside the mask)\n    # valid_pixels = valid_pixels[dist_from_centre:-dist_from_centre, dist_from_centre:-dist_from_centre]\n    valid_pixels[:dist_from_centre, :, 0] = -1\n    valid_pixels[-dist_from_centre:, :, 0] = -1\n    valid_pixels[:, :dist_from_centre, 0] = -1\n    valid_pixels[:, -dist_from_centre:, 0] = -1\n    #torch.Size([8181, 6330, 2]) --> torch.Size([8121, 6270, 2])\n    \n    x, y, w, h = evaluation_rectangle\n    pixels_inside_rect = valid_pixels[y:y+h+1, x:x+w+1].flatten(end_dim=1) \n    pixels_inside_rect = pixels_inside_rect[pixels_inside_rect[:, 0] != -1].numpy() # apply mask\n    \n    valid_pixels[y:y+h+1, x:x+w+1, 0] = -1\n    flattened = valid_pixels.flatten(end_dim=1)\n    pixels_outside_rect = flattened[flattened[:, 0] != -1].type(torch.int).numpy()\n    \n    print(f\"Time taken: {time.time()-t1:.2f} seconds | pixels_inside_rect: {pixels_inside_rect.shape[0]} | pixels_outside_rect: {pixels_outside_rect.shape[0]}\")\n    return pixels_inside_rect, pixels_outside_rect\n\npixels_inside_rect2, pixels_outside_rect2 = get_pixels()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T23:40:10.884562Z","iopub.execute_input":"2023-03-17T23:40:10.8851Z","iopub.status.idle":"2023-03-17T23:40:14.841047Z","shell.execute_reply.started":"2023-03-17T23:40:10.88505Z","shell.execute_reply":"2023-03-17T23:40:14.839776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BUFFER = dist_from_centre\nrect = evaluation_rectangle\n\nt1 = time.time()\nprint(\"Generating pixel lists...\")\n# Split our dataset into train and val. The pixels inside the rect are the \n# val set, and the pixels outside the rect are the train set.\npixels_inside_rect = []\npixels_outside_rect = []\nfor pixel in zip(*np.where(mask == 1)):\n    if pixel[1] < BUFFER or pixel[1] >= mask.shape[1]-BUFFER or pixel[0] < BUFFER or pixel[0] >= mask.shape[0]-BUFFER:\n        continue # Too close to the edge\n    if pixel[1] >= rect[0] and pixel[1] <= rect[0]+rect[2] and pixel[0] >= rect[1] and pixel[0] <= rect[1]+rect[3]:\n        pixels_inside_rect.append(pixel)\n    else:\n        pixels_outside_rect.append(pixel)\n\nprint(f\"Time taken: {time.time()-t1:.2f} seconds | pixels_inside_rect: {len(pixels_inside_rect)} | pixels_outside_rect: {len(pixels_outside_rect)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pixels_inside_rect2, np.array(pixels_inside_rect)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pixel coordinates match up perfectly :)\n\nprint((np.array(pixels_inside_rect) == pixels_inside_rect2).min())\nprint((np.array(pixels_outside_rect) == pixels_outside_rect2).min())","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}