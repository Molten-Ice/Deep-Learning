{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJVO0hhKBpCdwQl1rP3ynq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Molten-Ice/Deep-Learning/blob/dev/GPT_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20JDxGlWpK7u",
        "outputId": "b396325c-301f-4f27-c8cd-315b2be27a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi\n"
          ]
        }
      ],
      "source": [
        "print(\"Hi\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"foundation.txt\", 'r', encoding='utf-8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "TiGEb4vKpQYo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of dataset in characters: {len(text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww0xrhHZpdid",
        "outputId": "62ad1c58-ada5-4e63-8d5d-c4768fc4c177"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset in characters: 1240703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4S8DC43pksJ",
        "outputId": "1316fa36-2eef-4a01-c214-8121aa08bd70"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOUNDATION \n",
            "ISAAC ASIMOV \n",
            "\n",
            "\n",
            "Contents \n",
            "\n",
            "Introduction \n",
            "\n",
            "Part I The Psvchohistorians \n",
            "\n",
            "Part II The Encyclopedists \n",
            "\n",
            "Part III The Mayors \n",
            "\n",
            "Part IV The Traders \n",
            "\n",
            "Part V The Merchant Princes \n",
            "\n",
            "PART I \n",
            "\n",
            "THE PSYCHOHISTORIANS \n",
            "\n",
            "i. \n",
            "\n",
            "HARI SELDON-... bom In the 1 1,988th year of the Galactic Era; died 12,069. The dates are \n",
            "more commonly given In terms of the current Foundational Era as - 79 to the year 1 F.E. Born \n",
            "to middle-class parents on Flelicon, Arcturus sector (where his father, In a legend of doubtful \n",
            "authenticity, was a tobacco grower in the hydroponic plants of the planet), he early showed \n",
            "amazing ability in mathematics. Anecdotes concerning his ability are innumerable, and some \n",
            "are contradictory. At the age of two, he is said to have ... \n",
            "\n",
            "... Undoubtedly his greatest contributions were in the field of psychohistory. Seldon found the \n",
            "field little more than a set of vague axioms; he left it a profound statistical science.... \n",
            "\n",
            "... The best existing authority we have for the details\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FNlgCtxpqBw",
        "outputId": "1615803b-084c-433e-b630-668a41f53465"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !\"#%'()*,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ\\abcdefghijklmnopqrstuvwxyz—‘’”\n",
            "84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = {i:ch for ch, i in enumerate(chars)}\n",
        "itos = {ch:i for ch, i in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s] #encode, take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[n] for n in l])#decode, take a list of integers, output a string\n",
        "\n",
        "print(encode(\"Hello world!\"))\n",
        "print(decode(encode(\"Hello world!\")))"
      ],
      "metadata": {
        "id": "KjN3CiVWqbKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e15a7321-41d4-46d9-80b6-25bae0b5f574"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[34, 58, 65, 65, 68, 1, 76, 68, 71, 65, 57, 2]\n",
            "Hello world!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1_S0IxO7fk8",
        "outputId": "75bf070e-023e-4304-e19f-f8c6c943f0c1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1240703]) torch.int64\n",
            "tensor([32, 41, 47, 40, 30, 27, 46, 35, 41, 40,  1,  0, 35, 45, 27, 27, 29,  1,\n",
            "        27, 45, 35, 39, 41, 48,  1,  0,  0,  0, 29, 68, 67, 73, 58, 67, 73, 72,\n",
            "         1,  0,  0, 35, 67, 73, 71, 68, 57, 74, 56, 73, 62, 68, 67,  1,  0,  0,\n",
            "        42, 54, 71, 73,  1, 35,  1, 46, 61, 58,  1, 42, 72, 75, 56, 61, 68, 61,\n",
            "        62, 72, 73, 68, 71, 62, 54, 67, 72,  1,  0,  0, 42, 54, 71, 73,  1, 35,\n",
            "        35,  1, 46, 61, 58,  1, 31, 67, 56, 78, 56, 65, 68, 69, 58, 57, 62, 72,\n",
            "        73, 72,  1,  0,  0, 42, 54, 71, 73,  1, 35, 35, 35,  1, 46, 61, 58,  1,\n",
            "        39, 54, 78, 68, 71, 72,  1,  0,  0, 42, 54, 71, 73,  1, 35, 48,  1, 46,\n",
            "        61, 58,  1, 46, 71, 54, 57, 58, 71, 72,  1,  0,  0, 42, 54, 71, 73,  1,\n",
            "        48,  1, 46, 61, 58,  1, 39, 58, 71, 56, 61, 54, 67, 73,  1, 42, 71, 62,\n",
            "        67, 56, 58, 72,  1,  0,  0, 42, 27, 44, 46,  1, 35,  1,  0,  0, 46, 34,\n",
            "        31,  1, 42, 45, 51, 29, 34, 41, 34, 35, 45, 46, 41, 44, 35, 27, 40, 45,\n",
            "         1,  0,  0, 62, 12,  1,  0,  0, 34, 27, 44, 35,  1, 45, 31, 38, 30, 41,\n",
            "        40, 11, 12, 12, 12,  1, 55, 68, 66,  1, 35, 67,  1, 73, 61, 58,  1, 15,\n",
            "         1, 15, 10, 23, 22, 22, 73, 61,  1, 78, 58, 54, 71,  1, 68, 59,  1, 73,\n",
            "        61, 58,  1, 33, 54, 65, 54, 56, 73, 62, 56,  1, 31, 71, 54, 25,  1, 57,\n",
            "        62, 58, 57,  1, 15, 16, 10, 14, 20, 23, 12,  1, 46, 61, 58,  1, 57, 54,\n",
            "        73, 58, 72,  1, 54, 71, 58,  1,  0, 66, 68, 71, 58,  1, 56, 68, 66, 66,\n",
            "        68, 67, 65, 78,  1, 60, 62, 75, 58, 67,  1, 35, 67,  1, 73, 58, 71, 66,\n",
            "        72,  1, 68, 59,  1, 73, 61, 58,  1, 56, 74, 71, 71, 58, 67, 73,  1, 32,\n",
            "        68, 74, 67, 57, 54, 73, 62, 68, 67, 54, 65,  1, 31, 71, 54,  1, 54, 72,\n",
            "         1, 11,  1, 21, 23,  1, 73, 68,  1, 73, 61, 58,  1, 78, 58, 54, 71,  1,\n",
            "        15,  1, 32, 12, 31, 12,  1, 28, 68, 71, 67,  1,  0, 73, 68,  1, 66, 62,\n",
            "        57, 57, 65, 58, 11, 56, 65, 54, 72, 72,  1, 69, 54, 71, 58, 67, 73, 72,\n",
            "         1, 68, 67,  1, 32, 65, 58, 65, 62, 56, 68, 67, 10,  1, 27, 71, 56, 73,\n",
            "        74, 71, 74, 72,  1, 72, 58, 56, 73, 68, 71,  1,  7, 76, 61, 58, 71, 58,\n",
            "         1, 61, 62, 72,  1, 59, 54, 73, 61, 58, 71, 10,  1, 35, 67,  1, 54,  1,\n",
            "        65, 58, 60, 58, 67, 57,  1, 68, 59,  1, 57, 68, 74, 55, 73, 59, 74, 65,\n",
            "         1,  0, 54, 74, 73, 61, 58, 67, 73, 62, 56, 62, 73, 78, 10,  1, 76, 54,\n",
            "        72,  1, 54,  1, 73, 68, 55, 54, 56, 56, 68,  1, 60, 71, 68, 76, 58, 71,\n",
            "         1, 62, 67,  1, 73, 61, 58,  1, 61, 78, 57, 71, 68, 69, 68, 67, 62, 56,\n",
            "         1, 69, 65, 54, 67, 73, 72,  1, 68, 59,  1, 73, 61, 58,  1, 69, 65, 54,\n",
            "        67, 58, 73,  8, 10,  1, 61, 58,  1, 58, 54, 71, 65, 78,  1, 72, 61, 68,\n",
            "        76, 58, 57,  1,  0, 54, 66, 54, 79, 62, 67, 60,  1, 54, 55, 62, 65, 62,\n",
            "        73, 78,  1, 62, 67,  1, 66, 54, 73, 61, 58, 66, 54, 73, 62, 56, 72, 12,\n",
            "         1, 27, 67, 58, 56, 57, 68, 73, 58, 72,  1, 56, 68, 67, 56, 58, 71, 67,\n",
            "        62, 67, 60,  1, 61, 62, 72,  1, 54, 55, 62, 65, 62, 73, 78,  1, 54, 71,\n",
            "        58,  1, 62, 67, 67, 74, 66, 58, 71, 54, 55, 65, 58, 10,  1, 54, 67, 57,\n",
            "         1, 72, 68, 66, 58,  1,  0, 54, 71, 58,  1, 56, 68, 67, 73, 71, 54, 57,\n",
            "        62, 56, 73, 68, 71, 78, 12,  1, 27, 73,  1, 73, 61, 58,  1, 54, 60, 58,\n",
            "         1, 68, 59,  1, 73, 76, 68, 10,  1, 61, 58,  1, 62, 72,  1, 72, 54, 62,\n",
            "        57,  1, 73, 68,  1, 61, 54, 75, 58,  1, 12, 12, 12,  1,  0,  0, 12, 12,\n",
            "        12,  1, 47, 67, 57, 68, 74, 55, 73, 58, 57, 65, 78,  1, 61, 62, 72,  1,\n",
            "        60, 71, 58, 54, 73, 58, 72, 73,  1, 56, 68, 67, 73, 71, 62, 55, 74, 73,\n",
            "        62, 68, 67, 72,  1, 76, 58, 71, 58,  1, 62, 67,  1, 73, 61, 58,  1, 59,\n",
            "        62, 58, 65, 57,  1, 68, 59,  1, 69, 72, 78, 56, 61, 68, 61, 62, 72, 73,\n",
            "        68, 71, 78, 12,  1, 45, 58, 65, 57, 68, 67,  1, 59, 68, 74, 67, 57,  1,\n",
            "        73, 61, 58,  1,  0, 59, 62, 58, 65, 57,  1, 65, 62, 73, 73, 65, 58,  1,\n",
            "        66, 68, 71, 58,  1, 73, 61, 54, 67,  1, 54,  1, 72, 58, 73,  1, 68, 59,\n",
            "         1, 75, 54, 60, 74, 58,  1, 54, 77, 62, 68, 66, 72, 25,  1, 61, 58,  1,\n",
            "        65, 58, 59, 73,  1, 62, 73,  1, 54,  1, 69, 71, 68, 59, 68, 74, 67, 57,\n",
            "         1, 72, 73, 54, 73, 62, 72, 73, 62, 56, 54, 65,  1, 72, 56, 62, 58, 67,\n",
            "        56, 58, 12, 12, 12, 12,  1,  0,  0, 12, 12, 12,  1, 46, 61, 58,  1, 55,\n",
            "        58, 72, 73,  1, 58, 77, 62, 72, 73, 62, 67, 60,  1, 54, 74, 73, 61, 68,\n",
            "        71, 62, 73, 78,  1, 76, 58,  1, 61, 54, 75, 58,  1, 59, 68, 71,  1, 73,\n",
            "        61, 58,  1, 57, 58, 73, 54, 62, 65, 72])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(decode(x.item() for x in train_data[:100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZx1ntzi93hx",
        "outputId": "2c01cf4e-0c41-4c4e-a982-5bdc7bb9dccd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOUNDATION \n",
            "ISAAC ASIMOV \n",
            "\n",
            "\n",
            "Contents \n",
            "\n",
            "Introduction \n",
            "\n",
            "Part I The Psvchohistorians \n",
            "\n",
            "Part II The Ency\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHPtdrnC-E0R",
        "outputId": "66d749c1-87c7-4598-ef08-88958447df1b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([32, 41, 47, 40, 30, 27, 46, 35, 41])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(block_size):\n",
        "  context = train_data[:t+1]\n",
        "  target = train_data[t+1]\n",
        "  print(f\"when the input is {context} the target is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VnZ8GSf-gEM",
        "outputId": "9a1689de-4044-4ffc-cfa6-aaf949861e70"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when the input is tensor([32]) the target is 41\n",
            "when the input is tensor([32, 41]) the target is 47\n",
            "when the input is tensor([32, 41, 47]) the target is 40\n",
            "when the input is tensor([32, 41, 47, 40]) the target is 30\n",
            "when the input is tensor([32, 41, 47, 40, 30]) the target is 27\n",
            "when the input is tensor([32, 41, 47, 40, 30, 27]) the target is 46\n",
            "when the input is tensor([32, 41, 47, 40, 30, 27, 46]) the target is 35\n",
            "when the input is tensor([32, 41, 47, 40, 30, 27, 46, 35]) the target is 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(3)\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split=\"train\"):\n",
        "  data = train_data if split == \"train\" else val_data\n",
        "  ix = torch.randint(len(data)-block_size, (batch_size, ))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x, y\n",
        "\n",
        "xb, yb = get_batch()\n",
        "xb.shape, yb.shape\n",
        "xb, yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK3ZxyWX_KP6",
        "outputId": "92a2d773-b16f-4a9e-c48a-87dbd06f24fc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[54, 67, 57,  1, 73, 74, 71, 67],\n",
              "         [68, 69, 65, 58,  1, 56, 68, 67],\n",
              "         [67, 68,  1, 72, 62, 60, 67, 72],\n",
              "         [ 1, 42, 71, 62, 73, 56, 61, 58]]),\n",
              " tensor([[67, 57,  1, 73, 74, 71, 67, 58],\n",
              "         [69, 65, 58,  1, 56, 68, 67, 73],\n",
              "         [68,  1, 72, 62, 60, 67, 72,  1],\n",
              "         [42, 71, 62, 73, 56, 61, 58, 71]]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N_aOxjV_e3t",
        "outputId": "5155f921-4f3a-4c95-99c9-05baa64fc8c0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            "when input is [54] the target: 67\n",
            "when input is [54, 67] the target: 57\n",
            "when input is [54, 67, 57] the target: 1\n",
            "when input is [54, 67, 57, 1] the target: 73\n",
            "when input is [54, 67, 57, 1, 73] the target: 74\n",
            "when input is [54, 67, 57, 1, 73, 74] the target: 71\n",
            "when input is [54, 67, 57, 1, 73, 74, 71] the target: 67\n",
            "when input is [54, 67, 57, 1, 73, 74, 71, 67] the target: 58\n",
            "when input is [68] the target: 69\n",
            "when input is [68, 69] the target: 65\n",
            "when input is [68, 69, 65] the target: 58\n",
            "when input is [68, 69, 65, 58] the target: 1\n",
            "when input is [68, 69, 65, 58, 1] the target: 56\n",
            "when input is [68, 69, 65, 58, 1, 56] the target: 68\n",
            "when input is [68, 69, 65, 58, 1, 56, 68] the target: 67\n",
            "when input is [68, 69, 65, 58, 1, 56, 68, 67] the target: 73\n",
            "when input is [67] the target: 68\n",
            "when input is [67, 68] the target: 1\n",
            "when input is [67, 68, 1] the target: 72\n",
            "when input is [67, 68, 1, 72] the target: 62\n",
            "when input is [67, 68, 1, 72, 62] the target: 60\n",
            "when input is [67, 68, 1, 72, 62, 60] the target: 67\n",
            "when input is [67, 68, 1, 72, 62, 60, 67] the target: 72\n",
            "when input is [67, 68, 1, 72, 62, 60, 67, 72] the target: 1\n",
            "when input is [1] the target: 42\n",
            "when input is [1, 42] the target: 71\n",
            "when input is [1, 42, 71] the target: 62\n",
            "when input is [1, 42, 71, 62] the target: 73\n",
            "when input is [1, 42, 71, 62, 73] the target: 56\n",
            "when input is [1, 42, 71, 62, 73, 56] the target: 61\n",
            "when input is [1, 42, 71, 62, 73, 56, 61] the target: 58\n",
            "when input is [1, 42, 71, 62, 73, 56, 61, 58] the target: 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb) # input to the transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbIMxiQvBiKP",
        "outputId": "492ae436-4742-4ed3-b3da-86cd05a2923c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[54, 67, 57,  1, 73, 74, 71, 67],\n",
            "        [68, 69, 65, 58,  1, 56, 68, 67],\n",
            "        [67, 68,  1, 72, 62, 60, 67, 72],\n",
            "        [ 1, 42, 71, 62, 73, 56, 61, 58]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import einops\n",
        "except:\n",
        "    print(f\"einops not installed as required, installing...\")\n",
        "    !pip3 install einops\n",
        "    import einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI3v294_Ld5t",
        "outputId": "b377bf56-689d-4a5b-9d2b-3fbff41bc00b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "einops not installed as required, installing...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from einops import rearrange, reduce, repeat\n",
        "torch.manual_seed(3)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #Each token directly reads off the logit for the next token from a lookup table\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "\n",
        "    logits = self.token_embedding_table(idx) # (B, T, C) batch, time, channel\n",
        "    #[4, 8, 84])\n",
        "    if targets == None:\n",
        "      loss = None\n",
        "    else:\n",
        "      logits = rearrange(logits, 'B T C -> (B T) C')\n",
        "      targets = rearrange(targets, 'B T -> (B T)')\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    #idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "      #get the predicitions\n",
        "      logits, loss = self(idx)\n",
        "\n",
        "      #Focus on last time step\n",
        "      logits = logits[:, -1, :] # becomes (B, C)\n",
        "      #apply softmax to get probabilities\n",
        "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "      #sample from the distribution\n",
        "      \n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      # append sampled index to running sequence\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "    return idx\n",
        "\n",
        "\n",
        "m = BigramLanguageModel()\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "idx = torch.zeros((1, 1), dtype = torch.long)\n",
        "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2hVrQ7sErxv",
        "outputId": "c5b05b0b-f520-4d32-cec6-33af2dbdd370"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 84])\n",
            "tensor(4.9284, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "av3/—cT'A68XN/LE%L‘‘kkXeW)5d;ZE1s”-,zM8WJMh-GIVZ \n",
            ".””TY4f9nRG4kGd—kCy;p%9*/9yB\n",
            "DaFwiR7sH64e7QLWgV,,H\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "FXXlznxvE2_t"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "for steps in range(10000):\n",
        "\n",
        "  #sample a batch of data\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  #evaluate the loss\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmZJR4ZkFrY_",
        "outputId": "e08f17f5-06c5-49a5-881a-32acaf3b60a5"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5057151317596436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx, max_new_tokens=300)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1L65Ru0Q1n5",
        "outputId": "3a142c57-679e-420c-d09e-0d1416f9b078"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "here. stund s o h bure is waratonat I is \n",
            "\" FOcron ple \n",
            "\n",
            "my \n",
            "undengequre feresthardwecte sky. \n",
            "nkerin tesqu we lld kesthit looftt, ffow tr.\" \n",
            "Pr s lle weroullof reve wiots Q3: th,\"D, blo cadysctheted d aickedld det\" iven?\"MMUTHe wiave yovowisps bby trsir \n",
            "\"Warea solouthatifiminolyo sstordacer \n",
            "\n",
            "Fask\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The mathematical trick in self-attention"
      ],
      "metadata": {
        "id": "HXKzyU57RKOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#toy example\n",
        "B, T, C = 4, 8, 2\n",
        "x = torch.rand(B, T, C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvwgXe8JbYgq",
        "outputId": "4d5c9b29-c6f5-42ca-8a47-ee0931165f0d"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJS02OZfe9xv",
        "outputId": "d7b3442b-8c6b-401b-cdec-8dbdee8c378b"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev=x[b,:t+1] #(t, C)\n",
        "    xbow[b,t]=torch.mean(xprev, 0)\n",
        "xbow.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWgm5IBtbqXY",
        "outputId": "0b1b8fe9-d30f-4251-d94f-8733e98f80e4"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C)\n",
        "xbow2.shape, xbow2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzzaLZv1d0M1",
        "outputId": "fe23d08a-b316-4b3c-eeb6-c04cac986349"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 2]), tensor([[[0.2566, 0.7936],\n",
              "          [0.5987, 0.4634],\n",
              "          [0.7106, 0.5068],\n",
              "          [0.7503, 0.5220],\n",
              "          [0.7485, 0.5035],\n",
              "          [0.7713, 0.5152],\n",
              "          [0.6992, 0.5313],\n",
              "          [0.6455, 0.5200]],\n",
              " \n",
              "         [[0.2969, 0.8317],\n",
              "          [0.2011, 0.5506],\n",
              "          [0.2537, 0.4335],\n",
              "          [0.3271, 0.3267],\n",
              "          [0.4520, 0.2764],\n",
              "          [0.5243, 0.3275],\n",
              "          [0.4976, 0.3963],\n",
              "          [0.5077, 0.4598]],\n",
              " \n",
              "         [[0.5547, 0.3423],\n",
              "          [0.5945, 0.3534],\n",
              "          [0.6331, 0.5510],\n",
              "          [0.6721, 0.4836],\n",
              "          [0.6954, 0.5048],\n",
              "          [0.7052, 0.4532],\n",
              "          [0.6052, 0.4323],\n",
              "          [0.5441, 0.4920]],\n",
              " \n",
              "         [[0.6440, 0.7071],\n",
              "          [0.6511, 0.5992],\n",
              "          [0.7312, 0.4477],\n",
              "          [0.6812, 0.3755],\n",
              "          [0.6758, 0.3659],\n",
              "          [0.6721, 0.3709],\n",
              "          [0.7067, 0.3470],\n",
              "          [0.6436, 0.3289]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgwDmwFYd0cr",
        "outputId": "b73659f2-b9a7-4428-da6c-986597bf9c76"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0],xbow2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM_551lVeYci",
        "outputId": "f9e8c6a0-8575-4b0a-ea3d-786d84c09a8d"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.2463, 0.3751],\n",
              "         [0.3538, 0.4432],\n",
              "         [0.2456, 0.5110],\n",
              "         [0.2506, 0.6251],\n",
              "         [0.3025, 0.5521],\n",
              "         [0.2629, 0.4743],\n",
              "         [0.3585, 0.5094],\n",
              "         [0.4385, 0.4650]]), tensor([[0.2463, 0.3751],\n",
              "         [0.3538, 0.4432],\n",
              "         [0.2456, 0.5110],\n",
              "         [0.2506, 0.6251],\n",
              "         [0.3025, 0.5521],\n",
              "         [0.2629, 0.4743],\n",
              "         [0.3585, 0.5094],\n",
              "         [0.4385, 0.4650]]))"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tril(torch.ones(3, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlKtacnecPsY",
        "outputId": "415c0094-7afb-4860-b0a6-b05480d83927"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(wei)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnCXrJMkcoPX",
        "outputId": "b3059dc6-c176-4e87-f39e-ddc6128420bd"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self-attention (my attempt)\n",
        "# afternote, need to linearly project to get q,k,v at the start\n",
        "\n",
        "torch.manual_seed(3)\n",
        "B, T, C = 4, 8, 32 #batch, time, channels\n",
        "x = torch.randn(B, T, C)\n",
        "\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "#Query: What am I looking for\n",
        "#Key: What do I contain\n",
        "Q, K, V = torch.randn(B, T, C), torch.randn(B, T, C), torch.randn(B, T, C)\n",
        "wei = Q @ rearrange(K, 'B T C -> B C T')\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "out = wei @ V\n",
        "wei.shape, wei[0][:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpYxheh-dnZ0",
        "outputId": "2902e938-578f-406e-ef91-2cf52704797d"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 8]),\n",
              " tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "          0.0000e+00, 0.0000e+00],\n",
              "         [3.1798e-03, 9.9682e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "          0.0000e+00, 0.0000e+00],\n",
              "         [2.6990e-01, 1.2181e-03, 7.2888e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "          0.0000e+00, 0.0000e+00],\n",
              "         [9.9784e-01, 2.9594e-10, 2.1637e-03, 3.2028e-09, 0.0000e+00, 0.0000e+00,\n",
              "          0.0000e+00, 0.0000e+00],\n",
              "         [9.9892e-01, 4.9244e-09, 1.0709e-03, 7.5832e-06, 2.9531e-08, 0.0000e+00,\n",
              "          0.0000e+00, 0.0000e+00],\n",
              "         [6.2417e-05, 8.8304e-01, 1.1058e-05, 3.7488e-02, 7.9403e-02, 4.6288e-09,\n",
              "          0.0000e+00, 0.0000e+00],\n",
              "         [1.9431e-03, 9.9065e-01, 7.3533e-03, 3.4129e-08, 2.2347e-08, 6.9649e-08,\n",
              "          5.4451e-05, 0.0000e+00],\n",
              "         [2.9305e-08, 4.7222e-06, 1.8114e-12, 9.7270e-01, 2.7292e-02, 1.1133e-08,\n",
              "          1.2229e-06, 6.8476e-07]]))"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape, out[0][:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCOPX7XpfHBS",
        "outputId": "1d336a02-8a5f-451c-ac71-f7a79864f0fe"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 32]),\n",
              " tensor([[-5.3579e-01,  2.2411e+00, -1.0500e+00,  2.6850e-01,  8.9653e-01,\n",
              "          -2.2838e-01,  1.7261e+00, -9.0125e-01, -9.8739e-02, -9.4091e-01,\n",
              "          -1.7678e+00,  1.7666e-01,  4.8473e-01, -2.0531e-01,  2.2039e+00,\n",
              "          -6.0018e-01,  1.3860e+00, -6.2178e-01, -1.4932e+00,  1.2155e+00,\n",
              "           4.9699e-02,  7.8623e-01, -6.7045e-01,  1.1508e+00,  5.9142e-01,\n",
              "          -2.7558e+00,  1.0268e+00, -1.0699e+00, -4.2805e-01,  2.3318e+00,\n",
              "          -3.3652e-01,  4.0867e-01],\n",
              "         [ 1.1780e+00,  1.4106e+00, -2.2665e-01,  1.3992e+00, -3.9619e-01,\n",
              "          -1.4221e+00, -5.7917e-01,  7.4531e-01, -3.9628e-03, -1.7195e+00,\n",
              "          -4.6205e-01,  6.5826e-01, -8.9226e-01, -2.2795e-01,  2.4093e+00,\n",
              "           2.2689e+00, -3.5392e-01,  1.2998e+00,  6.3739e-01,  1.3966e+00,\n",
              "          -7.3228e-01, -1.0222e+00,  1.0640e+00,  2.1083e-01, -1.2269e-02,\n",
              "           1.4459e+00,  6.3121e-01,  7.8775e-01, -1.5463e-01,  2.0462e-01,\n",
              "          -4.7826e-01,  2.8160e-01],\n",
              "         [-8.0958e-01,  6.2532e-01,  1.1800e+00, -1.2699e-02, -3.2259e-01,\n",
              "          -7.5749e-01,  1.1619e+00, -2.8712e-01,  5.5664e-02, -4.5603e-01,\n",
              "           2.8078e-01,  8.4317e-03,  7.5758e-01, -1.1935e+00,  1.2038e+00,\n",
              "          -1.8664e-01,  1.7390e+00, -7.2359e-01, -1.7080e+00,  1.7634e+00,\n",
              "          -3.3303e-01,  7.2907e-01,  3.6087e-01,  7.3755e-01, -8.9802e-02,\n",
              "          -1.0508e-01,  9.6050e-01, -5.8854e-04,  8.4658e-02,  7.7528e-01,\n",
              "           6.7015e-01,  9.1096e-01]]))"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self-attention (Andrej version)"
      ],
      "metadata": {
        "id": "fn7N6yhEi7fI"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(3)\n",
        "B,T,C=4,8,32\n",
        "x=torch.randn(B,T,C)\n",
        "\n",
        "#single self-attention head\n",
        "head_size=16\n",
        "key=nn.Linear(C,head_size,bias=False)\n",
        "query=nn.Linear(C,head_size,bias=False)\n",
        "value=nn.Linear(C,head_size,bias=False)\n",
        "k = key(x) # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "v = value(x)\n",
        "\n",
        "wei = q @ rearrange(k, 'B T C -> B C T')\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "out = wei @ v\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3gh1rL9jk-B",
        "outputId": "6fee403e-c2dc-4bc9-eced-f8660dad7dab"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdfiFDaFk5og",
        "outputId": "4a0d5e04-d37e-47de-a192-1325431bab83"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3835, 0.6165, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1507, 0.2281, 0.6212, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0507, 0.0230, 0.7846, 0.1417, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2544, 0.2024, 0.4529, 0.0681, 0.0223, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1009, 0.5172, 0.1604, 0.1195, 0.0186, 0.0835, 0.0000, 0.0000],\n",
              "        [0.1076, 0.0954, 0.0025, 0.0086, 0.7683, 0.0080, 0.0097, 0.0000],\n",
              "        [0.2585, 0.0457, 0.0329, 0.0113, 0.0118, 0.3126, 0.2737, 0.0535]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYnDuTOnluqM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}