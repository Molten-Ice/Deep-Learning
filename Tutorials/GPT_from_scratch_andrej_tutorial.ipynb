{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUzqpuGbmS85nXiJ5KyjTN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Molten-Ice/Deep-Learning/blob/dev/Tutorials/GPT_from_scratch_andrej_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20JDxGlWpK7u",
        "outputId": "762c12ea-af88-4bc4-b705-48c7e07e004a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi\n"
          ]
        }
      ],
      "source": [
        "print(\"Hi\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"foundation.txt\", 'r', encoding='utf-8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "TiGEb4vKpQYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of dataset in characters: {len(text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww0xrhHZpdid",
        "outputId": "ab8488a4-74c9-431f-f17e-ae8bb0774304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset in characters: 1240703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4S8DC43pksJ",
        "outputId": "bc6c4c13-fb0d-4a19-c035-615a83cde3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOUNDATION \n",
            "ISAAC ASIMOV \n",
            "\n",
            "\n",
            "Contents \n",
            "\n",
            "Introduction \n",
            "\n",
            "Part I The Psvchohistorians \n",
            "\n",
            "Part II The Encyclopedists \n",
            "\n",
            "Part III The Mayors \n",
            "\n",
            "Part IV The Traders \n",
            "\n",
            "Part V The Merchant Princes \n",
            "\n",
            "PART I \n",
            "\n",
            "THE PSYCHOHISTORIANS \n",
            "\n",
            "i. \n",
            "\n",
            "HARI SELDON-... bom In the 1 1,988th year of the Galactic Era; died 12,069. The dates are \n",
            "more commonly given In terms of the current Foundational Era as - 79 to the year 1 F.E. Born \n",
            "to middle-class parents on Flelicon, Arcturus sector (where his father, In a legend of doubtful \n",
            "authenticity, was a tobacco grower in the hydroponic plants of the planet), he early showed \n",
            "amazing ability in mathematics. Anecdotes concerning his ability are innumerable, and some \n",
            "are contradictory. At the age of two, he is said to have ... \n",
            "\n",
            "... Undoubtedly his greatest contributions were in the field of psychohistory. Seldon found the \n",
            "field little more than a set of vague axioms; he left it a profound statistical science.... \n",
            "\n",
            "... The best existing authority we have for the details\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FNlgCtxpqBw",
        "outputId": "393a2e77-b0f8-41a7-d765-2586561aaac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !\"#%'()*,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ\\abcdefghijklmnopqrstuvwxyz—‘’”\n",
            "84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = {i:ch for ch, i in enumerate(chars)}\n",
        "itos = {ch:i for ch, i in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s] #encode, take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[n] for n in l])#decode, take a list of integers, output a string\n",
        "\n",
        "print(encode(\"Hello world!\"))\n",
        "print(decode(encode(\"Hello world!\")))"
      ],
      "metadata": {
        "id": "KjN3CiVWqbKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1876010a-3915-46bb-abdc-8316224d0f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[34, 58, 65, 65, 68, 1, 76, 68, 71, 65, 57, 2]\n",
            "Hello world!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1_S0IxO7fk8",
        "outputId": "5579a648-bb60-4204-82ae-ad2ce1a64b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1240703]) torch.int64\n",
            "tensor([32, 41, 47, 40, 30, 27, 46, 35, 41, 40,  1,  0, 35, 45, 27, 27, 29,  1,\n",
            "        27, 45, 35, 39, 41, 48,  1,  0,  0,  0, 29, 68, 67, 73, 58, 67, 73, 72,\n",
            "         1,  0,  0, 35, 67, 73, 71, 68, 57, 74, 56, 73, 62, 68, 67,  1,  0,  0,\n",
            "        42, 54, 71, 73,  1, 35,  1, 46, 61, 58,  1, 42, 72, 75, 56, 61, 68, 61,\n",
            "        62, 72, 73, 68, 71, 62, 54, 67, 72,  1,  0,  0, 42, 54, 71, 73,  1, 35,\n",
            "        35,  1, 46, 61, 58,  1, 31, 67, 56, 78, 56, 65, 68, 69, 58, 57, 62, 72,\n",
            "        73, 72,  1,  0,  0, 42, 54, 71, 73,  1, 35, 35, 35,  1, 46, 61, 58,  1,\n",
            "        39, 54, 78, 68, 71, 72,  1,  0,  0, 42, 54, 71, 73,  1, 35, 48,  1, 46,\n",
            "        61, 58,  1, 46, 71, 54, 57, 58, 71, 72,  1,  0,  0, 42, 54, 71, 73,  1,\n",
            "        48,  1, 46, 61, 58,  1, 39, 58, 71, 56, 61, 54, 67, 73,  1, 42, 71, 62,\n",
            "        67, 56, 58, 72,  1,  0,  0, 42, 27, 44, 46,  1, 35,  1,  0,  0, 46, 34,\n",
            "        31,  1, 42, 45, 51, 29, 34, 41, 34, 35, 45, 46, 41, 44, 35, 27, 40, 45,\n",
            "         1,  0,  0, 62, 12,  1,  0,  0, 34, 27, 44, 35,  1, 45, 31, 38, 30, 41,\n",
            "        40, 11, 12, 12, 12,  1, 55, 68, 66,  1, 35, 67,  1, 73, 61, 58,  1, 15,\n",
            "         1, 15, 10, 23, 22, 22, 73, 61,  1, 78, 58, 54, 71,  1, 68, 59,  1, 73,\n",
            "        61, 58,  1, 33, 54, 65, 54, 56, 73, 62, 56,  1, 31, 71, 54, 25,  1, 57,\n",
            "        62, 58, 57,  1, 15, 16, 10, 14, 20, 23, 12,  1, 46, 61, 58,  1, 57, 54,\n",
            "        73, 58, 72,  1, 54, 71, 58,  1,  0, 66, 68, 71, 58,  1, 56, 68, 66, 66,\n",
            "        68, 67, 65, 78,  1, 60, 62, 75, 58, 67,  1, 35, 67,  1, 73, 58, 71, 66,\n",
            "        72,  1, 68, 59,  1, 73, 61, 58,  1, 56, 74, 71, 71, 58, 67, 73,  1, 32,\n",
            "        68, 74, 67, 57, 54, 73, 62, 68, 67, 54, 65,  1, 31, 71, 54,  1, 54, 72,\n",
            "         1, 11,  1, 21, 23,  1, 73, 68,  1, 73, 61, 58,  1, 78, 58, 54, 71,  1,\n",
            "        15,  1, 32, 12, 31, 12,  1, 28, 68, 71, 67,  1,  0, 73, 68,  1, 66, 62,\n",
            "        57, 57, 65, 58, 11, 56, 65, 54, 72, 72,  1, 69, 54, 71, 58, 67, 73, 72,\n",
            "         1, 68, 67,  1, 32, 65, 58, 65, 62, 56, 68, 67, 10,  1, 27, 71, 56, 73,\n",
            "        74, 71, 74, 72,  1, 72, 58, 56, 73, 68, 71,  1,  7, 76, 61, 58, 71, 58,\n",
            "         1, 61, 62, 72,  1, 59, 54, 73, 61, 58, 71, 10,  1, 35, 67,  1, 54,  1,\n",
            "        65, 58, 60, 58, 67, 57,  1, 68, 59,  1, 57, 68, 74, 55, 73, 59, 74, 65,\n",
            "         1,  0, 54, 74, 73, 61, 58, 67, 73, 62, 56, 62, 73, 78, 10,  1, 76, 54,\n",
            "        72,  1, 54,  1, 73, 68, 55, 54, 56, 56, 68,  1, 60, 71, 68, 76, 58, 71,\n",
            "         1, 62, 67,  1, 73, 61, 58,  1, 61, 78, 57, 71, 68, 69, 68, 67, 62, 56,\n",
            "         1, 69, 65, 54, 67, 73, 72,  1, 68, 59,  1, 73, 61, 58,  1, 69, 65, 54,\n",
            "        67, 58, 73,  8, 10,  1, 61, 58,  1, 58, 54, 71, 65, 78,  1, 72, 61, 68,\n",
            "        76, 58, 57,  1,  0, 54, 66, 54, 79, 62, 67, 60,  1, 54, 55, 62, 65, 62,\n",
            "        73, 78,  1, 62, 67,  1, 66, 54, 73, 61, 58, 66, 54, 73, 62, 56, 72, 12,\n",
            "         1, 27, 67, 58, 56, 57, 68, 73, 58, 72,  1, 56, 68, 67, 56, 58, 71, 67,\n",
            "        62, 67, 60,  1, 61, 62, 72,  1, 54, 55, 62, 65, 62, 73, 78,  1, 54, 71,\n",
            "        58,  1, 62, 67, 67, 74, 66, 58, 71, 54, 55, 65, 58, 10,  1, 54, 67, 57,\n",
            "         1, 72, 68, 66, 58,  1,  0, 54, 71, 58,  1, 56, 68, 67, 73, 71, 54, 57,\n",
            "        62, 56, 73, 68, 71, 78, 12,  1, 27, 73,  1, 73, 61, 58,  1, 54, 60, 58,\n",
            "         1, 68, 59,  1, 73, 76, 68, 10,  1, 61, 58,  1, 62, 72,  1, 72, 54, 62,\n",
            "        57,  1, 73, 68,  1, 61, 54, 75, 58,  1, 12, 12, 12,  1,  0,  0, 12, 12,\n",
            "        12,  1, 47, 67, 57, 68, 74, 55, 73, 58, 57, 65, 78,  1, 61, 62, 72,  1,\n",
            "        60, 71, 58, 54, 73, 58, 72, 73,  1, 56, 68, 67, 73, 71, 62, 55, 74, 73,\n",
            "        62, 68, 67, 72,  1, 76, 58, 71, 58,  1, 62, 67,  1, 73, 61, 58,  1, 59,\n",
            "        62, 58, 65, 57,  1, 68, 59,  1, 69, 72, 78, 56, 61, 68, 61, 62, 72, 73,\n",
            "        68, 71, 78, 12,  1, 45, 58, 65, 57, 68, 67,  1, 59, 68, 74, 67, 57,  1,\n",
            "        73, 61, 58,  1,  0, 59, 62, 58, 65, 57,  1, 65, 62, 73, 73, 65, 58,  1,\n",
            "        66, 68, 71, 58,  1, 73, 61, 54, 67,  1, 54,  1, 72, 58, 73,  1, 68, 59,\n",
            "         1, 75, 54, 60, 74, 58,  1, 54, 77, 62, 68, 66, 72, 25,  1, 61, 58,  1,\n",
            "        65, 58, 59, 73,  1, 62, 73,  1, 54,  1, 69, 71, 68, 59, 68, 74, 67, 57,\n",
            "         1, 72, 73, 54, 73, 62, 72, 73, 62, 56, 54, 65,  1, 72, 56, 62, 58, 67,\n",
            "        56, 58, 12, 12, 12, 12,  1,  0,  0, 12, 12, 12,  1, 46, 61, 58,  1, 55,\n",
            "        58, 72, 73,  1, 58, 77, 62, 72, 73, 62, 67, 60,  1, 54, 74, 73, 61, 68,\n",
            "        71, 62, 73, 78,  1, 76, 58,  1, 61, 54, 75, 58,  1, 59, 68, 71,  1, 73,\n",
            "        61, 58,  1, 57, 58, 73, 54, 62, 65, 72])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(decode(x.item() for x in train_data[:100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZx1ntzi93hx",
        "outputId": "e127db5e-40a6-45ce-cadf-888e3067d0b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOUNDATION \n",
            "ISAAC ASIMOV \n",
            "\n",
            "\n",
            "Contents \n",
            "\n",
            "Introduction \n",
            "\n",
            "Part I The Psvchohistorians \n",
            "\n",
            "Part II The Ency\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHPtdrnC-E0R",
        "outputId": "dceeab62-cc81-421a-ebe6-35156bc3aa33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([32, 41, 47, 40, 30, 27, 46, 35, 41])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(block_size):\n",
        "  context = train_data[:t+1]\n",
        "  target = train_data[t+1]\n",
        "  print(f\"when the input is {context} the target is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VnZ8GSf-gEM",
        "outputId": "c8492666-8609-4888-be71-f78e6290eef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when the input is tensor([32]) the target is 41\n",
            "when the input is tensor([32, 41]) the target is 47\n",
            "when the input is tensor([32, 41, 47]) the target is 40\n",
            "when the input is tensor([32, 41, 47, 40]) the target is 30\n",
            "when the input is tensor([32, 41, 47, 40, 30]) the target is 27\n",
            "when the input is tensor([32, 41, 47, 40, 30, 27]) the target is 46\n",
            "when the input is tensor([32, 41, 47, 40, 30, 27, 46]) the target is 35\n",
            "when the input is tensor([32, 41, 47, 40, 30, 27, 46, 35]) the target is 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(3)\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split=\"train\"):\n",
        "  data = train_data if split == \"train\" else val_data\n",
        "  ix = torch.randint(len(data)-block_size, (batch_size, ))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x, y\n",
        "\n",
        "xb, yb = get_batch()\n",
        "xb.shape, yb.shape\n",
        "xb, yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK3ZxyWX_KP6",
        "outputId": "0508ee0d-2ed8-4365-d1cb-3a403402e5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[54, 67, 57,  1, 73, 74, 71, 67],\n",
              "         [68, 69, 65, 58,  1, 56, 68, 67],\n",
              "         [67, 68,  1, 72, 62, 60, 67, 72],\n",
              "         [ 1, 42, 71, 62, 73, 56, 61, 58]]),\n",
              " tensor([[67, 57,  1, 73, 74, 71, 67, 58],\n",
              "         [69, 65, 58,  1, 56, 68, 67, 73],\n",
              "         [68,  1, 72, 62, 60, 67, 72,  1],\n",
              "         [42, 71, 62, 73, 56, 61, 58, 71]]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N_aOxjV_e3t",
        "outputId": "3140dd46-0aad-4615-d569-28e8dc0f8eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            "when input is [54] the target: 67\n",
            "when input is [54, 67] the target: 57\n",
            "when input is [54, 67, 57] the target: 1\n",
            "when input is [54, 67, 57, 1] the target: 73\n",
            "when input is [54, 67, 57, 1, 73] the target: 74\n",
            "when input is [54, 67, 57, 1, 73, 74] the target: 71\n",
            "when input is [54, 67, 57, 1, 73, 74, 71] the target: 67\n",
            "when input is [54, 67, 57, 1, 73, 74, 71, 67] the target: 58\n",
            "when input is [68] the target: 69\n",
            "when input is [68, 69] the target: 65\n",
            "when input is [68, 69, 65] the target: 58\n",
            "when input is [68, 69, 65, 58] the target: 1\n",
            "when input is [68, 69, 65, 58, 1] the target: 56\n",
            "when input is [68, 69, 65, 58, 1, 56] the target: 68\n",
            "when input is [68, 69, 65, 58, 1, 56, 68] the target: 67\n",
            "when input is [68, 69, 65, 58, 1, 56, 68, 67] the target: 73\n",
            "when input is [67] the target: 68\n",
            "when input is [67, 68] the target: 1\n",
            "when input is [67, 68, 1] the target: 72\n",
            "when input is [67, 68, 1, 72] the target: 62\n",
            "when input is [67, 68, 1, 72, 62] the target: 60\n",
            "when input is [67, 68, 1, 72, 62, 60] the target: 67\n",
            "when input is [67, 68, 1, 72, 62, 60, 67] the target: 72\n",
            "when input is [67, 68, 1, 72, 62, 60, 67, 72] the target: 1\n",
            "when input is [1] the target: 42\n",
            "when input is [1, 42] the target: 71\n",
            "when input is [1, 42, 71] the target: 62\n",
            "when input is [1, 42, 71, 62] the target: 73\n",
            "when input is [1, 42, 71, 62, 73] the target: 56\n",
            "when input is [1, 42, 71, 62, 73, 56] the target: 61\n",
            "when input is [1, 42, 71, 62, 73, 56, 61] the target: 58\n",
            "when input is [1, 42, 71, 62, 73, 56, 61, 58] the target: 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb) # input to the transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbIMxiQvBiKP",
        "outputId": "7ecd1197-8a27-4138-9432-3eb412793e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[54, 67, 57,  1, 73, 74, 71, 67],\n",
            "        [68, 69, 65, 58,  1, 56, 68, 67],\n",
            "        [67, 68,  1, 72, 62, 60, 67, 72],\n",
            "        [ 1, 42, 71, 62, 73, 56, 61, 58]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import einops\n",
        "except:\n",
        "    print(f\"einops not installed as required, installing...\")\n",
        "    !pip3 install einops\n",
        "    import einops"
      ],
      "metadata": {
        "id": "CI3v294_Ld5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from einops import rearrange, reduce, repeat\n",
        "torch.manual_seed(3)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #Each token directly reads off the logit for the next token from a lookup table\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "\n",
        "    logits = self.token_embedding_table(idx) # (B, T, C) batch, time, channel\n",
        "    #[4, 8, 84])\n",
        "    if targets == None:\n",
        "      loss = None\n",
        "    else:\n",
        "      logits = rearrange(logits, 'B T C -> (B T) C')\n",
        "      targets = rearrange(targets, 'B T -> (B T)')\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    #idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "      #get the predicitions\n",
        "      logits, loss = self(idx)\n",
        "\n",
        "      #Focus on last time step\n",
        "      logits = logits[:, -1, :] # becomes (B, C)\n",
        "      #apply softmax to get probabilities\n",
        "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "      #sample from the distribution\n",
        "      \n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      # append sampled index to running sequence\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "    return idx\n",
        "\n",
        "\n",
        "m = BigramLanguageModel()\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "idx = torch.zeros((1, 1), dtype = torch.long)\n",
        "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2hVrQ7sErxv",
        "outputId": "3eee5601-62a0-4222-84d7-112dd6b0807a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 84])\n",
            "tensor(4.9284, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "av3/—cT'A68XN/LE%L‘‘kkXeW)5d;ZE1s”-,zM8WJMh-GIVZ \n",
            ".””TY4f9nRG4kGd—kCy;p%9*/9yB\n",
            "DaFwiR7sH64e7QLWgV,,H\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "FXXlznxvE2_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "for steps in range(10000):\n",
        "\n",
        "  #sample a batch of data\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  #evaluate the loss\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmZJR4ZkFrY_",
        "outputId": "c68229dc-61af-4e7b-9529-67950157b409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3158881664276123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx, max_new_tokens=300)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1L65Ru0Q1n5",
        "outputId": "9c57ed35-d2c4-4b59-c13e-03c1351f9311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"Youroowis \n",
            "\" Ke t \n",
            "\"ORiomor blobyofind yesede -k,\" mo. akwheerd \n",
            "\n",
            "Cher touno Nof tin \n",
            "Share sor indes woratow'sto p bed -wanguto l ing st ilce vend id., hen, aldor. ont Pen ghinccandreigherentuisnle \n",
            "\" ak? icond, wengly his aly Noras l pre, wartis fr stilont ally in irererltre de rine \n",
            "\n",
            "f whmsppps \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The mathematical trick in self-attention"
      ],
      "metadata": {
        "id": "HXKzyU57RKOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#toy example\n",
        "B, T, C = 4, 8, 2\n",
        "x = torch.rand(B, T, C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvwgXe8JbYgq",
        "outputId": "405c0bf4-1739-4d77-b322-f91b34edbc0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJS02OZfe9xv",
        "outputId": "37e954fc-916d-4cfe-b15d-d49677fd95f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev=x[b,:t+1] #(t, C)\n",
        "    xbow[b,t]=torch.mean(xprev, 0)\n",
        "xbow.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWgm5IBtbqXY",
        "outputId": "1236512d-4553-4ac6-c9c1-dd335e636b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C)\n",
        "xbow2.shape, xbow2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzzaLZv1d0M1",
        "outputId": "af692216-080e-4c71-bf39-14c8306e8fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 2]), tensor([[[0.3199, 0.9329],\n",
              "          [0.2211, 0.9348],\n",
              "          [0.2060, 0.7641],\n",
              "          [0.2101, 0.7790],\n",
              "          [0.1774, 0.6962],\n",
              "          [0.2743, 0.5942],\n",
              "          [0.2872, 0.5450],\n",
              "          [0.3209, 0.5052]],\n",
              " \n",
              "         [[0.0414, 0.6998],\n",
              "          [0.1315, 0.6451],\n",
              "          [0.3959, 0.6086],\n",
              "          [0.3549, 0.6772],\n",
              "          [0.3660, 0.5527],\n",
              "          [0.4262, 0.5293],\n",
              "          [0.3883, 0.5443],\n",
              "          [0.4144, 0.5962]],\n",
              " \n",
              "         [[0.2405, 0.0219],\n",
              "          [0.2705, 0.0158],\n",
              "          [0.2658, 0.2286],\n",
              "          [0.2983, 0.3950],\n",
              "          [0.3111, 0.3728],\n",
              "          [0.3794, 0.4181],\n",
              "          [0.4098, 0.4430],\n",
              "          [0.3612, 0.4671]],\n",
              " \n",
              "         [[0.9030, 0.9143],\n",
              "          [0.4728, 0.9273],\n",
              "          [0.4710, 0.7030],\n",
              "          [0.4953, 0.7608],\n",
              "          [0.4975, 0.7072],\n",
              "          [0.5069, 0.6566],\n",
              "          [0.5208, 0.6680],\n",
              "          [0.5357, 0.6292]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgwDmwFYd0cr",
        "outputId": "bf7deecd-bfc1-4b83-de57-9139268c6a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0],xbow2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM_551lVeYci",
        "outputId": "13701a89-45ae-4cac-e285-e16451485d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.3199, 0.9329],\n",
              "         [0.2211, 0.9348],\n",
              "         [0.2060, 0.7641],\n",
              "         [0.2101, 0.7790],\n",
              "         [0.1774, 0.6962],\n",
              "         [0.2743, 0.5942],\n",
              "         [0.2872, 0.5450],\n",
              "         [0.3209, 0.5052]]), tensor([[0.3199, 0.9329],\n",
              "         [0.2211, 0.9348],\n",
              "         [0.2060, 0.7641],\n",
              "         [0.2101, 0.7790],\n",
              "         [0.1774, 0.6962],\n",
              "         [0.2743, 0.5942],\n",
              "         [0.2872, 0.5450],\n",
              "         [0.3209, 0.5052]]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tril(torch.ones(3, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlKtacnecPsY",
        "outputId": "b27b806b-f430-48a7-8af9-5129270da3fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(wei)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnCXrJMkcoPX",
        "outputId": "d6c10801-b2f0-46a0-dd8c-30f648188d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self-attention (my attempt)\n",
        "# afternote, need to linearly project to get q,k,v at the start\n",
        "\n",
        "torch.manual_seed(3)\n",
        "B, T, C = 4, 8, 32 #batch, time, channels\n",
        "x = torch.randn(B, T, C)\n",
        "\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "#Query: What am I looking for\n",
        "#Key: What do I contain\n",
        "Q, K, V = torch.randn(B, T, C), torch.randn(B, T, C), torch.randn(B, T, C)\n",
        "wei = Q @ rearrange(K, 'B T C -> B C T')\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "out = wei @ V\n",
        "wei.shape, wei[0][:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpYxheh-dnZ0",
        "outputId": "76f9fc23-4bd6-421f-b385-aa05f54713f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 8]),\n",
              " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0032, 0.9968, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.2699, 0.0012, 0.7289, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape, out[0][:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCOPX7XpfHBS",
        "outputId": "ad5947c9-3fd2-4904-bad0-d6143dfc9032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 16]),\n",
              " tensor([[-0.0209, -0.4611,  0.6770, -0.4637, -1.3853,  0.4191,  0.1293,  0.9245,\n",
              "           0.5460,  0.2836,  0.1412, -0.2600, -0.5766, -0.5271,  0.6131,  0.5250],\n",
              "         [ 0.1207, -0.0291, -0.1975, -0.1703, -0.5137, -0.2041, -0.3989,  0.5389,\n",
              "          -0.3234,  0.2389, -0.2635,  0.1992, -0.2563, -0.4836,  0.1775,  0.2862],\n",
              "         [ 0.7711,  0.3065,  0.1448, -0.1141, -0.3625, -0.0264,  0.3279,  0.3900,\n",
              "           0.1979, -0.1840,  0.1636,  0.1665,  0.3929, -0.1639, -0.1987, -0.2770]],\n",
              "        grad_fn=<SliceBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self-attention (Andrej version)"
      ],
      "metadata": {
        "id": "fn7N6yhEi7fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(3)\n",
        "B,T,C=4,8,32\n",
        "x=torch.randn(B,T,C)\n",
        "\n",
        "#single self-attention head\n",
        "head_size=16\n",
        "key=nn.Linear(C,head_size,bias=False)\n",
        "query=nn.Linear(C,head_size,bias=False)\n",
        "value=nn.Linear(C,head_size,bias=False)\n",
        "k = key(x) # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "v = value(x)\n",
        "\n",
        "wei = q @ rearrange(k, 'B T C -> B C T')\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "out = wei @ v\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3gh1rL9jk-B",
        "outputId": "d60f4026-320c-45e4-aa35-93be1bb42440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdfiFDaFk5og",
        "outputId": "fbb07ad9-b9ea-439f-8e95-569a1b572752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3835, 0.6165, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1507, 0.2281, 0.6212, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0507, 0.0230, 0.7846, 0.1417, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2544, 0.2024, 0.4529, 0.0681, 0.0223, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1009, 0.5172, 0.1604, 0.1195, 0.0186, 0.0835, 0.0000, 0.0000],\n",
              "        [0.1076, 0.0954, 0.0025, 0.0086, 0.7683, 0.0080, 0.0097, 0.0000],\n",
              "        [0.2585, 0.0457, 0.0329, 0.0113, 0.0118, 0.3126, 0.2737, 0.0535]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.randn(B, T, head_size)\n",
        "q = torch.randn(B, T, head_size)\n",
        "wei = q @ k.transpose(-2, -1) * (head_size**-0.5)\n",
        "print(k.var(), q.var())\n",
        "print(wei.var())"
      ],
      "metadata": {
        "id": "RYnDuTOnluqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2d358a-9873-42e9-8388-4c144a318b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9504) tensor(1.0232)\n",
            "tensor(0.9685)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OHJlVqCYYA9",
        "outputId": "2d578499-7fb1-421a-cc54-ac452cdb3c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8225,  0.2513, -1.1796,  0.2286, -0.0963,  0.9684, -1.2620,  0.2212],\n",
              "        [ 2.4607,  1.6196,  0.2774,  0.1037,  1.7921,  1.5087, -1.1270, -0.6625],\n",
              "        [ 0.1954, -1.7517,  0.1640,  1.0055,  0.0459, -1.8845,  1.3148, -0.2771],\n",
              "        [-2.0184, -0.1616, -0.1218, -0.1139,  1.0969,  0.4771, -0.4557, -0.4467],\n",
              "        [-1.9438,  1.1667, -0.7137,  1.3427, -0.2675, -2.2083, -0.3305, -1.8594],\n",
              "        [ 0.6739,  0.3095,  0.0882,  0.2718,  0.0699, -1.2526,  0.5267,  0.2534],\n",
              "        [ 0.1975, -0.3789, -0.9172,  0.1914, -0.4382,  0.9326,  0.1505,  1.5192],\n",
              "        [-0.2842,  1.0991, -0.0356, -0.6142, -0.7021,  0.4700, -1.3805,  0.2360]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, 0.5]), dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl4Z5OHSYi9w",
        "outputId": "7d026e83-4394-47bf-ed27-12ef5443c053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2245, 0.1663, 0.2742, 0.3349])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, 0.5])*8, dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wq5IAb4YrLC",
        "outputId": "0e75d151-ced5-4908-9c78-9897d7603cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0327, 0.0030, 0.1620, 0.8023])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm:\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.ones(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    xmean = x.mean(-1, keepdim=True)\n",
        "    xvar = x.var(-1, keepdim=True)\n",
        "    xhat = (x-xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    return self.out\n",
        "  \n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "module = LayerNorm(100)\n",
        "x = torch.rand(32, 100)\n",
        "x = module(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyNhaTd3iHWT",
        "outputId": "2905a728-e4c4-44f8-c23c-1f7f355dbf53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS8yPkoOi4VL",
        "outputId": "29f2e505-911b-4a77-f7ab-501458bc62a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.3455e+00,  2.6194e+00,  2.0827e+00,  1.3762e+00,  2.9404e-01,\n",
              "        -1.2090e-02,  2.5746e-01,  7.3188e-01,  1.5219e+00, -1.8476e-01,\n",
              "         7.3477e-01,  1.7242e+00,  2.5107e+00,  1.3145e+00,  1.2971e+00,\n",
              "         5.0545e-01,  2.1720e+00,  8.3857e-01, -2.8253e-05,  2.4993e+00,\n",
              "        -2.8490e-01, -5.5096e-01,  2.5085e+00,  1.6450e+00,  7.0065e-01,\n",
              "         2.6866e-01,  1.4610e+00,  1.1637e+00, -5.9129e-01,  2.1673e+00,\n",
              "         1.0234e+00,  2.5926e+00,  2.8687e-01, -2.4771e-01,  2.5922e+00,\n",
              "         1.2024e+00,  1.7027e+00, -5.4927e-02,  1.3871e+00,  8.1647e-01,\n",
              "         2.2686e+00,  1.9890e+00,  1.4315e+00,  1.3788e+00, -5.9318e-01,\n",
              "         1.6901e+00, -4.0116e-01,  2.5742e+00,  2.2766e+00,  4.6099e-01,\n",
              "         3.5855e-01,  2.0046e+00,  1.5602e+00,  9.3168e-01,  1.2217e+00,\n",
              "         1.7688e+00,  1.6342e+00,  7.4533e-01,  1.0405e-01, -1.4352e-01,\n",
              "        -6.6179e-02, -1.3787e-01, -4.2803e-01,  1.9904e+00,  2.4511e+00,\n",
              "        -7.2737e-02, -5.1592e-01,  1.7863e-01,  4.4438e-02,  2.5114e+00,\n",
              "         1.1695e+00,  2.2667e-01,  1.5162e+00, -4.9847e-01,  5.1802e-01,\n",
              "        -4.6031e-01,  2.1923e-01, -2.3308e-01, -1.6056e-01,  2.1878e+00,\n",
              "         3.4408e-01,  1.9008e+00,  2.9959e-01,  1.5478e+00,  7.4996e-01,\n",
              "         2.5005e+00,  1.6091e+00, -4.4420e-01, -4.0390e-01,  1.7157e+00,\n",
              "         1.2783e+00, -2.6270e-01,  2.6131e+00,  1.3620e+00,  2.3437e+00,\n",
              "        -5.6887e-01,  1.0861e+00,  1.3474e+00,  1.3570e+00,  1.5059e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# residual connections are super important\n",
        "# linearly project multi-head attention output, then dropout\n",
        "\n",
        "#feed forward linear(n, 4n), GeLU, linear(4n, n), dropout\n",
        "\n",
        "#pre norm formulation, creates gradient super highway!\n",
        "#layer norm before it goes into self-attention and feedforward\n",
        "\n",
        "#add layer norms after block before final linear layer\n",
        "\n",
        "#scaling up module\n",
        "#dropout after softmax\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 64 # how many independent sequences will we process in parallel?\n",
        "block_size = 256 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "id": "vuvIZTUNYt4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}